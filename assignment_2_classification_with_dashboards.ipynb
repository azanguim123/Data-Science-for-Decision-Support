{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M8waroY6-gTv",
        "outputId": "170b301c-8bd8-43f0-efe5-c7750eafd4de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset shape: (14999, 10)\n",
            "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
            "0                0.38             0.53               2                   157   \n",
            "1                0.80             0.86               5                   262   \n",
            "2                0.11             0.88               7                   272   \n",
            "3                0.72             0.87               5                   223   \n",
            "4                0.37             0.52               2                   159   \n",
            "\n",
            "   time_spend_company  Work_accident  left  promotion_last_5years Department  \\\n",
            "0                   3              0     1                      0      sales   \n",
            "1                   6              0     1                      0      sales   \n",
            "2                   4              0     1                      0      sales   \n",
            "3                   5              0     1                      0      sales   \n",
            "4                   3              0     1                      0      sales   \n",
            "\n",
            "   salary  \n",
            "0     low  \n",
            "1  medium  \n",
            "2  medium  \n",
            "3     low  \n",
            "4     low  \n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 4552, number of negative: 9105\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001811 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 893\n",
            "[LightGBM] [Info] Number of data points in the train set: 13657, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333309 -> initscore=-0.693257\n",
            "[LightGBM] [Info] Start training from score -0.693257\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "                    Model  Train Accuracy  Test Accuracy  Precision    Recall  \\\n",
            "0     Logistic Regression        0.777477       0.788333   0.788223  0.788333   \n",
            "1           Decision Tree        0.993776       0.978000   0.978051  0.978000   \n",
            "2  Support Vector Machine        0.956140       0.948333   0.948597  0.948333   \n",
            "3     k-Nearest Neighbors        0.978326       0.946333   0.950162  0.946333   \n",
            "4           Random Forest        0.979205       0.977667   0.978008  0.977667   \n",
            "5                 XGBoost        0.995900       0.986333   0.986295  0.986333   \n",
            "6                CatBoost        0.997291       0.987000   0.986962  0.987000   \n",
            "7               Light GBM        0.989017       0.981667   0.981734  0.981667   \n",
            "\n",
            "   F1 Score  \n",
            "0  0.788278  \n",
            "1  0.978023  \n",
            "2  0.948454  \n",
            "3  0.947372  \n",
            "4  0.977311  \n",
            "5  0.986279  \n",
            "6  0.986962  \n",
            "7  0.981482  \n",
            "Top 3 Models by Test Accuracy:\n",
            "       Model  Train Accuracy  Test Accuracy  Precision    Recall  F1 Score\n",
            "6   CatBoost        0.997291       0.987000   0.986962  0.987000  0.986962\n",
            "5    XGBoost        0.995900       0.986333   0.986295  0.986333  0.986279\n",
            "7  Light GBM        0.989017       0.981667   0.981734  0.981667  0.981482\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"3040bb48-c56b-4aee-a602-3f620b7160b0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3040bb48-c56b-4aee-a602-3f620b7160b0\")) {                    Plotly.newPlot(                        \"3040bb48-c56b-4aee-a602-3f620b7160b0\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Model=%{x}\\u003cbr\\u003eTest Accuracy=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"CatBoost\",\"XGBoost\",\"Light GBM\"],\"xaxis\":\"x\",\"y\":[0.987,0.9863333333333333,0.9816666666666667],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Model\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Test Accuracy\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Top 3 Models by Test Accuracy (Loaded Parameters)\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3040bb48-c56b-4aee-a602-3f620b7160b0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "import json\n",
        "from dash import Dash, html, dcc, Input, Output\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "import catboost\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# Load Dataset\n",
        "df = pd.read_csv('/content/HR_comma_sep.csv')\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(df.head())\n",
        "\n",
        "# Preprocessing\n",
        "df = pd.get_dummies(df, drop_first=True)  # One-hot encode categorical features\n",
        "X = df.drop(columns=['left'])  # Features\n",
        "Y = df['left']  # Target\n",
        "\n",
        "# Split Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=195)\n",
        "\n",
        "# Scale Features\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote_ratio = 0.5\n",
        "smote = SMOTE(random_state=42, sampling_strategy=smote_ratio)\n",
        "X_train_smote, Y_train_smote = smote.fit_resample(X_train_scaled, Y_train)\n",
        "\n",
        "# Initialize Models\n",
        "\n",
        "\n",
        "new_models = {\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=195),\n",
        "    \"XGBoost\": xgb.XGBClassifier(objective=\"binary:logistic\", random_state=195),\n",
        "    \"CatBoost\": catboost.CatBoostClassifier(learning_rate=0.1, iterations=500, depth=6, verbose=0, random_state=195),\n",
        "    \"Light GBM\": lgb.LGBMClassifier(random_state=195)\n",
        "}\n",
        "new_param_grids = {\n",
        "    \"Random Forest\": {\n",
        "        \"n_estimators\": [50, 100, 200],\n",
        "        \"max_depth\": [3, 5, 7],\n",
        "        \"min_samples_split\": [2, 5, 10],\n",
        "        \"min_samples_leaf\": [1, 2, 4],\n",
        "        \"max_features\": ['sqrt', 'log2', None]\n",
        "    },\n",
        "    \"XGBoost\": {\n",
        "        \"learning_rate\": [0.01, 0.05, 0.1],\n",
        "        \"n_estimators\": [50, 100, 200],\n",
        "        \"max_depth\": [3, 5, 7],\n",
        "        \"min_child_weight\": [1, 5, 10],\n",
        "        \"gamma\": [0, 0.1, 0.3],\n",
        "        \"subsample\": [0.6, 0.8],\n",
        "        \"colsample_bytree\": [0.6, 0.8]\n",
        "    },\n",
        "    \"CatBoost\": {\n",
        "        \"learning_rate\": [0.01, 0.03, 0.05],\n",
        "        \"depth\": [4, 6, 8],\n",
        "        \"l2_leaf_reg\": [3, 5, 7],\n",
        "        \"border_count\": [32, 64, 128]\n",
        "    },\n",
        "    \"LightGBM\": {\n",
        "        \"learning_rate\": [0.01, 0.03, 0.05],\n",
        "        \"n_estimators\": [50, 100, 200],\n",
        "        \"max_depth\": [3, 5, 7],\n",
        "        \"num_leaves\": [15, 31, 50],\n",
        "        \"min_data_in_leaf\": [20, 30, 40],\n",
        "        \"lambda_l1\": [0, 0.1, 0.5],\n",
        "        \"lambda_l2\": [0, 0.1, 0.5]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Commented out GridSearchCV part and load saved parameters\n",
        "\"\"\"\n",
        "# Perform GridSearchCV for each new model\n",
        "new_best_params = {}\n",
        "new_results = []\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=195)\n",
        "for model_name, model in new_models.items():\n",
        "    grid = GridSearchCV(model, new_param_grids[model_name], cv=kf, scoring='accuracy')\n",
        "    grid.fit(X_train_smote, Y_train_smote)\n",
        "\n",
        "    # Store best parameters and results\n",
        "    new_best_params[model_name] = grid.best_params_\n",
        "    best_model = grid.best_estimator_\n",
        "\n",
        "    # Evaluate the best model\n",
        "    train_accuracy = accuracy_score(Y_train_smote, best_model.predict(X_train_smote))\n",
        "    test_accuracy = accuracy_score(Y_test, best_model.predict(X_test_scaled))\n",
        "\n",
        "    new_results.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Train Accuracy\": train_accuracy,\n",
        "        \"Test Accuracy\": test_accuracy\n",
        "    })\n",
        "\n",
        "# Save the best hyperparameters for new models to a JSON file\n",
        "new_params_path = '/content/drive/My Drive/best_superhyperparameters_classification_newmodels_assignment_2.json'\n",
        "with open(new_params_path, \"w\") as f:\n",
        "    json.dump(new_best_params, f)\n",
        "\"\"\"\n",
        "# Load Best Parameters for New Models\n",
        "new_best_params_path = '/content/drive/My Drive/best_superhyperparameters_classification_newmodels_assignment_2.json'\n",
        "with open(new_best_params_path, \"r\") as f:\n",
        "    new_best_params = json.load(f)\n",
        "\n",
        "# Re-initialize New Models with Best Parameters\n",
        "optimized_new_models = {\n",
        "    \"Random Forest\": RandomForestClassifier(**new_best_params[\"Random Forest\"], random_state=195),\n",
        "    \"XGBoost\": xgb.XGBClassifier(**new_best_params[\"XGBoost\"], objective=\"binary:logistic\", random_state=195),\n",
        "    \"CatBoost\": catboost.CatBoostClassifier(**new_best_params[\"CatBoost\"], verbose=0, random_state=195),\n",
        "    \"Light GBM\": lgb.LGBMClassifier(**new_best_params[\"LightGBM\"], random_state=195)\n",
        "}\n",
        "\n",
        "# Load Best Parameters for Old Models\n",
        "best_params_path = '/content/drive/My Drive/best_hyperparameters_classification_oldmodels.json'\n",
        "with open(best_params_path, \"r\") as f:\n",
        "    best_params = json.load(f)\n",
        "\n",
        "# Re-initialize Old Models with Best Parameters\n",
        "optimized_old_models = {\n",
        "    \"Logistic Regression\": LogisticRegression(**best_params[\"Logistic Regression\"]),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(**best_params[\"Decision Tree\"], random_state=195),\n",
        "    \"Support Vector Machine\": SVC(**best_params[\"Support Vector Machine\"]),\n",
        "    \"k-Nearest Neighbors\": KNeighborsClassifier(**best_params[\"K-Nearest Neighbors\"])\n",
        "}\n",
        "\n",
        "# Combine All Models\n",
        "all_models = {}\n",
        "all_models.update(optimized_old_models)\n",
        "all_models.update(optimized_new_models)\n",
        "\n",
        "# Train and Evaluate Models\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "model_metrics = []\n",
        "for model_name, model in all_models.items():\n",
        "    # Train with SMOTE data\n",
        "    model.fit(X_train_smote, Y_train_smote)\n",
        "\n",
        "    # Predict on Train and Test sets\n",
        "    Y_train_pred = model.predict(X_train_smote)\n",
        "    Y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # Calculate Metrics\n",
        "    train_accuracy = accuracy_score(Y_train_smote, Y_train_pred)\n",
        "    test_accuracy = accuracy_score(Y_test, Y_test_pred)\n",
        "    precision = precision_score(Y_test, Y_test_pred, average='weighted')\n",
        "    recall = recall_score(Y_test, Y_test_pred, average='weighted')\n",
        "    f1 = f1_score(Y_test, Y_test_pred, average='weighted')\n",
        "\n",
        "    # Append Metrics\n",
        "    model_metrics.append([model_name, train_accuracy, test_accuracy, precision, recall, f1])\n",
        "\n",
        "# Create a DataFrame for Metrics Comparison\n",
        "model_metrics_df = pd.DataFrame(model_metrics, columns=[\"Model\", \"Train Accuracy\", \"Test Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "print(model_metrics_df)\n",
        "\n",
        "# Save Metrics to a File\n",
        "metrics_path = '/content/drive/My Drive/classification_model_metrics.json'\n",
        "model_metrics_df.to_json(metrics_path)\n",
        "\n",
        "# Identify the Top 3 Models by Test Accuracy\n",
        "top_3_models = model_metrics_df.sort_values(by=\"Test Accuracy\", ascending=False).head(3)\n",
        "print(\"Top 3 Models by Test Accuracy:\")\n",
        "print(top_3_models)\n",
        "\n",
        "\n",
        "\n",
        "# Plot top 3 models\n",
        "fig = px.bar(top_3_models, x='Model', y='Test Accuracy', title=\"Top 3 Models by Test Accuracy (Loaded Parameters)\")\n",
        "fig.show()\n",
        "\n",
        "# Initialize the Dash App\n",
        "app = Dash(__name__)\n",
        "\n",
        "# List of top 3 models and corresponding hyperparameters\n",
        "top_3_models_list = top_3_models['Model'].tolist()\n",
        "\n",
        "# Dashboard Layout\n",
        "app.layout = html.Div([\n",
        "    # Title with Names and Matriculation Numbers\n",
        "    html.H1(\"Classification Dashboard - Majd al hallack (604516) & Azanguim Ndongmo Larry Nelson (603846)\",\n",
        "            style={'textAlign': 'center', 'color': '#E7E585'}),\n",
        "\n",
        "    # Checklist/Select Widget for Model Selection\n",
        "    html.Label(\"Select Models to Compare:\"),\n",
        "    dcc.Checklist(\n",
        "        id='model-checklist',\n",
        "        options=[{'label': model, 'value': model} for model in top_3_models_list],\n",
        "        value=top_3_models_list,  # Default selection\n",
        "        inline=True\n",
        "    ),\n",
        "\n",
        "    # Tabs for Dashboard Pages\n",
        "    dcc.Tabs([\n",
        "        # Page 1: Data & Hyperparameters\n",
        "        dcc.Tab(label='Page 1: Data & Hyperparameters', children=[\n",
        "            html.Div(id='page1-content')\n",
        "        ]),\n",
        "\n",
        "        # Page 2: Performance Metrics\n",
        "        dcc.Tab(label='Page 2: Performance Metrics', children=[\n",
        "            html.Div(id='page2-content')\n",
        "        ]),\n",
        "\n",
        "        # Page 3: Forecasting Results\n",
        "        dcc.Tab(label='Page 3: Forecasting Results', children=[\n",
        "            html.Div(id='page3-content')\n",
        "        ])\n",
        "    ])\n",
        "])\n",
        "\n",
        "\n",
        "# Callbacks for Page 1: Show Head of Data and Hyperparameters\n",
        "@app.callback(\n",
        "    Output('page1-content', 'children'),\n",
        "    Input('model-checklist', 'value')\n",
        ")\n",
        "def update_page1(models_selected):\n",
        "    if not models_selected:\n",
        "        return [html.H3(\"No models selected. Please select at least one model.\")]\n",
        "\n",
        "    content = []\n",
        "    content.append(html.H3(\"Head of Pre-processed Data\"))\n",
        "    content.append(html.Pre(df.head().to_string()))\n",
        "\n",
        "    content.append(html.H3(\"Hyperparameters for Selected Models\"))\n",
        "    for model in models_selected:\n",
        "        hyperparams = new_best_params.get(model, \"No hyperparameters found.\")\n",
        "        content.append(html.P(f\"{model}: {hyperparams}\"))\n",
        "    return content\n",
        "\n",
        "\n",
        "# Callbacks for Page 2: Show Performance Metrics\n",
        "@app.callback(\n",
        "    Output('page2-content', 'children'),\n",
        "    Input('model-checklist', 'value')\n",
        ")\n",
        "def update_page2(models_selected):\n",
        "    # Debug: print selected models\n",
        "    print(\"Models selected:\", models_selected)\n",
        "\n",
        "    # Handle case when no models are selected\n",
        "    if not models_selected:\n",
        "        return html.Div([\n",
        "            html.H3(\"Performance Metrics\"),\n",
        "            html.P(\"Please select one or more models to see the performance metrics.\")\n",
        "        ])\n",
        "\n",
        "    # Filter performance results based on selected models\n",
        "    filtered_results = model_metrics_df[model_metrics_df['Model'].isin(models_selected)]\n",
        "\n",
        "    # Debug: print filtered results\n",
        "    print(\"Filtered results:\\n\", filtered_results)\n",
        "\n",
        "    # Handle case when no models match the selected models\n",
        "    if filtered_results.empty:\n",
        "        return html.Div([\n",
        "            html.H3(\"Performance Metrics\"),\n",
        "            html.P(\"No performance data available for the selected models.\")\n",
        "        ])\n",
        "\n",
        "    # Generate performance table\n",
        "    table = html.Table([html.Tr([html.Th(col) for col in filtered_results.columns])] + [\n",
        "        html.Tr([html.Td(filtered_results.iloc[i][col]) for col in filtered_results.columns])\n",
        "        for i in range(len(filtered_results))\n",
        "    ])\n",
        "\n",
        "    # Generate Bar Chart for Accuracy\n",
        "    fig = go.Figure()\n",
        "    for model in models_selected:\n",
        "        accuracy = filtered_results[filtered_results['Model'] == model]['Test Accuracy'].values[0]\n",
        "        fig.add_trace(go.Bar(name=model, x=['Accuracy'], y=[accuracy]))\n",
        "\n",
        "    fig.update_layout(barmode='group', title=\"Test Accuracy Comparison\")\n",
        "\n",
        "    # Return the updated content for page2\n",
        "    return [\n",
        "        html.H3(\"Performance Metrics\"),\n",
        "        table,\n",
        "        dcc.Graph(figure=fig)\n",
        "    ]\n",
        "\n",
        "# Callbacks for Page 3: Forecasting Results\n",
        "@app.callback(\n",
        "    Output('page3-content', 'children'),\n",
        "    Input('model-checklist', 'value')\n",
        ")\n",
        "def update_page3(models_selected):\n",
        "    if not models_selected or len(models_selected) < 2:\n",
        "        return [html.H3(\"Please select at least two models for forecasting.\")]\n",
        "\n",
        "    # Placeholder for forecasting data\n",
        "    forecasting_data = pd.DataFrame({\n",
        "        'True Value': [1, 0, 1, 0],\n",
        "        f'{models_selected[0]} Prediction': [1, 0, 1, 0],\n",
        "        f'{models_selected[1]} Prediction': [1, 0, 0, 1]\n",
        "    })\n",
        "\n",
        "    forecasting_data['Wrong Classifications'] = forecasting_data.iloc[:, 1:].ne(\n",
        "        forecasting_data['True Value'], axis=0).sum(axis=1)\n",
        "    forecasting_data = forecasting_data.sort_values(by='Wrong Classifications', ascending=False)\n",
        "\n",
        "    table = html.Table([\n",
        "        html.Tr([html.Th(col) for col in forecasting_data.columns])\n",
        "    ] + [\n",
        "        html.Tr([html.Td(forecasting_data.iloc[i][col]) for col in forecasting_data.columns])\n",
        "        for i in range(len(forecasting_data))\n",
        "    ])\n",
        "\n",
        "    return [html.H3(\"Forecasting Results\"), table]\n",
        "\n",
        "\n",
        "# Run the app\n",
        "if __name__ == '__main__':\n",
        "    app.run_server(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trying to improve further more by applying classvoting\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# GridSearchCV results (best parameters from previous search)\n",
        "rf_best_params = {\"max_depth\": 7, \"max_features\": None, \"min_samples_leaf\": 1, \"min_samples_split\": 2, \"n_estimators\": 100}\n",
        "xgb_best_params = {\"colsample_bytree\": 0.8, \"gamma\": 0, \"learning_rate\": 0.1, \"max_depth\": 7, \"min_child_weight\": 1, \"n_estimators\": 200, \"subsample\": 0.6}\n",
        "catboost_best_params = {\"border_count\": 128, \"depth\": 8, \"l2_leaf_reg\": 7, \"learning_rate\": 0.05}\n",
        "lgbm_best_params = {\"lambda_l1\": 0, \"lambda_l2\": 0, \"learning_rate\": 0.05, \"max_depth\": 7, \"min_data_in_leaf\": 20, \"n_estimators\": 200, \"num_leaves\": 50}\n",
        "\n",
        "# Initialize individual models with the best parameters\n",
        "rf_model = RandomForestClassifier(**rf_best_params)\n",
        "xgb_model = xgb.XGBClassifier(**xgb_best_params)\n",
        "catboost_model = CatBoostClassifier(**catboost_best_params, silent=True)\n",
        "lgbm_model = lgb.LGBMClassifier(**lgbm_best_params)\n",
        "\n",
        "# Create a VotingClassifier (majority voting)\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('random_forest', rf_model),\n",
        "    ('xgboost', xgb_model),\n",
        "    ('catboost', catboost_model),\n",
        "    ('lightgbm', lgbm_model)\n",
        "], voting='hard')\n",
        "\n",
        "# Train all individual models and the Voting Classifier\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('random_forest', rf_model),\n",
        "    ('xgboost', xgb_model),\n",
        "    ('catboost', catboost_model),\n",
        "    ('lightgbm', lgbm_model)\n",
        "], voting='soft', weights=[1, 4, 8, 2])  # Adjust weights to get the best out of the top performing models like catboost,xgboost,and lightGBM\n",
        "\n",
        "# Initialize dictionary to store evaluation metrics\n",
        "model_metrics = []\n",
        "\n",
        "# Train and evaluate each model\n",
        "for model_name, model in models.items():\n",
        "    # Fit the model\n",
        "    model.fit(X_train_smote, Y_train_smote)\n",
        "\n",
        "    # Predict on the test set\n",
        "    Y_train_pred = model.predict(X_train_smote)\n",
        "    Y_test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # Calculate metrics\n",
        "    train_accuracy = accuracy_score(Y_train_smote, Y_train_pred)\n",
        "    test_accuracy = accuracy_score(Y_test, Y_test_pred)\n",
        "    precision = precision_score(Y_test, Y_test_pred, average='weighted')\n",
        "    recall = recall_score(Y_test, Y_test_pred, average='weighted')\n",
        "    f1 = f1_score(Y_test, Y_test_pred, average='weighted')\n",
        "\n",
        "    # Append metrics to the list\n",
        "    model_metrics.append([model_name, train_accuracy, test_accuracy, precision, recall, f1])\n",
        "\n",
        "# Create a DataFrame for Metrics Comparison\n",
        "model_metrics_df = pd.DataFrame(model_metrics, columns=[\"Model\", \"Train Accuracy\", \"Test Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "\n",
        "# Print the comparison of all models\n",
        "print(model_metrics_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDf-VGdepKXr",
        "outputId": "73282ad7-3a61-47fe-aacb-4def989b5230"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 4552, number of negative: 9105\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009973 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 893\n",
            "[LightGBM] [Info] Number of data points in the train set: 13657, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333309 -> initscore=-0.693257\n",
            "[LightGBM] [Info] Start training from score -0.693257\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 4552, number of negative: 9105\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001861 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 893\n",
            "[LightGBM] [Info] Number of data points in the train set: 13657, number of used features: 18\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333309 -> initscore=-0.693257\n",
            "[LightGBM] [Info] Start training from score -0.693257\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "               Model  Train Accuracy  Test Accuracy  Precision    Recall  \\\n",
            "0      Random Forest        0.978839       0.978667   0.979068  0.978667   \n",
            "1            XGBoost        0.996046       0.985333   0.985289  0.985333   \n",
            "2           CatBoost        0.996851       0.987667   0.987639  0.987667   \n",
            "3           LightGBM        0.989017       0.981667   0.981734  0.981667   \n",
            "4  Voting Classifier        0.989383       0.982667   0.982835  0.982667   \n",
            "\n",
            "   F1 Score  \n",
            "0  0.978321  \n",
            "1  0.985271  \n",
            "2  0.987617  \n",
            "3  0.981482  \n",
            "4  0.982467  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dash\n",
        "!pip install catboost"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sgBrtIehdlKt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}